# üí¨ Chat Multi-Cliente em Python com AI Bot

Um sistema de chat completo desenvolvido em Python com socket programming, suportando mensagens de texto, envio de arquivos, comunica√ß√£o privada/global e integra√ß√£o com AI via Ollama.

## ‚ú® Funcionalidades

### Chat B√°sico
- üåê **Mensagens Globais**: Envie mensagens para todos os usu√°rios conectados
- üîí **Mensagens Privadas**: Converse diretamente com usu√°rios espec√≠ficos
- üìé **Envio de Arquivos**: Compartilhe arquivos de qualquer tipo (com interface gr√°fica)
- üë• **Lista de Usu√°rios Online**: Veja quem est√° conectado em tempo real
- üìú **Hist√≥rico de Mensagens**: Mensagens globais s√£o mantidas para novos usu√°rios
- üíæ **Download de Arquivos**: Receba e salve arquivos automaticamente
- üõ°Ô∏è **Interface Thread-Safe**: Evita conflitos de entrada simult√¢nea
- üîç **Descoberta Autom√°tica**: Encontra o servidor na rede local automaticamente

### AI Bot (Novo!)
- ü§ñ **ChatBot Inteligente**: Bot AI que responde automaticamente mensagens privadas
- üß† **Integra√ß√£o Ollama**: Utiliza modelos locais de IA (Qwen, Llama, etc.)
- üéØ **Respostas Contextuais**: Processa e responde perguntas em linguagem natural
- üîÑ **Funcionamento Autom√°tico**: Conecta e responde sem interven√ß√£o manual
- üìä **Monitoramento**: Logs detalhados de atividade e status de conex√£o

## üöÄ Como Executar

### Pr√©-requisitos

- Python 3.6 ou superior
- Biblioteca `tkinter` (geralmente inclu√≠da no Python)
- **Para o AI Bot**: [Ollama](https://ollama.ai) instalado localmente

### Configura√ß√£o do AI Bot (Opcional)

1. **Instale o Ollama:**
   ```bash
   # Linux/macOS
   curl -fsSL https://ollama.ai/install.sh | sh
   
   # Windows: Baixe de https://ollama.ai/download
   ```

2. **Baixe um modelo de IA:**
   ```bash
   ollama pull qwen2.5:4b  # Modelo recomendado (leve)
   # ou
   ollama pull llama3.2     # Modelo alternativo
   ```

3. **Inicie o servidor Ollama:**
   ```bash
   ollama serve
   ```

### Executando no Terminal

1. **Clone o reposit√≥rio:**
   ```bash
   git clone <url-do-repositorio>
   cd chat-python
   ```

2. **Execute o servidor:**
   ```bash
   python server.py
   ```

3. **Execute o(s) cliente(s) em terminais separados:**
   ```bash
   python client.py
   ```

4. **Execute o AI Bot (opcional):**
   ```bash
   python ai_client.py
   ```

### üí° Executando no VS Code com Terminais Divididos

#### M√©todo 1: Usando o Terminal Integrado

1. **Abra o VS Code** na pasta do projeto
2. **Abra o terminal integrado**: `Ctrl + ` ` (backtick) ou `View > Terminal`
3. **Divida o terminal**:
   - Clique no √≠cone **"+"** no canto superior direito do terminal
   - Ou use `Ctrl + Shift + 5` para dividir o terminal
   - Ou clique no √≠cone **"Split Terminal"** (√≠cone de divis√£o)

4. **Execute os programas**:
   - **Terminal 1**: `python server.py`
   - **Terminal 2**: `python client.py`
   - **Terminal 3**: `python ai_client.py` (opcional - AI Bot)
   - **Terminal 4** (opcional): `python client.py` (mais clientes)

#### M√©todo 2: Usando M√∫ltiplas Abas de Terminal

1. **Terminal 1**: `Ctrl + Shift + ` ` (novo terminal)
2. **Terminal 2**: Clique no **"+"** para criar nova aba
3. **Terminal 3**: Repita conforme necess√°rio

#### M√©todo 3: Usando a Paleta de Comandos

1. Pressione `Ctrl + Shift + P`
2. Digite "Terminal: Create New Terminal"
3. Repita para criar m√∫ltiplos terminais

## üéÆ Como Usar

### Primeiro Uso

1. **Inicie o servidor** primeiro
2. **(Opcional) Inicie o AI Bot** se quiser ter assistente IA
3. **Execute um ou mais clientes**
4. **Digite seu nome** quando solicitado
5. **Navegue pelo menu** com as op√ß√µes numeradas

### Menu Principal

```
üìã MENU PRINCIPAL
==========================================

Escolha uma op√ß√£o:
1. üåê Mensagem global (todos)
2. üîí Mensagem privada
3. üë• Listar usu√°rios online
4. ‚ùå Sair
```

### Enviando Mensagens

- **Mensagem de Texto**: Digite sua mensagem normalmente
- **Envio de Arquivo**: Selecione um arquivo atrav√©s da interface gr√°fica
- **Mensagem Privada**: Digite o nome exato do destinat√°rio

### Interagindo com o AI Bot

1. **Certifique-se que o ChatBot est√° online** (use op√ß√£o 3 para verificar)
2. **Envie uma mensagem privada** (op√ß√£o 2)
3. **Digite "ChatBot"** como destinat√°rio
4. **Fa√ßa sua pergunta** em linguagem natural
5. **Aguarde a resposta** do bot

**Exemplos de perguntas para o ChatBot:**
- "Qual √© a capital do Brasil?"
- "Explique como funciona a internet"
- "Conte uma piada"
- "Resuma a hist√≥ria da Segunda Guerra Mundial"
- "Como fazer um bolo de chocolate?"

### Recebendo Arquivos

Quando receber um arquivo, voc√™ ver√°:

```
==================================================
üìé ARQUIVO RECEBIDO
üë§ De: Jo√£o
üìÑ Arquivo: documento.pdf
üìä Tamanho: 245.3KB
==================================================
O que deseja fazer?
1. üíæ Baixar arquivo
2. ‚ùå Ignorar
```

Os arquivos baixados s√£o salvos na pasta `downloads/`.

## üìÅ Estrutura do Projeto

```
chat-python/
‚îú‚îÄ‚îÄ server.py          # Servidor principal do chat
‚îú‚îÄ‚îÄ client.py          # Cliente humano do chat
‚îú‚îÄ‚îÄ ai_client.py       # Cliente AI Bot (novo!)
‚îú‚îÄ‚îÄ downloads/         # (criada automaticamente) Arquivos recebidos
‚îî‚îÄ‚îÄ README.md          # Este arquivo
```

## üîß Configura√ß√£o

### Alterando IP/Porta

**No servidor** (`server.py`):
```python
SERVER_IP = "0.0.0.0"  # Aceita de qualquer IP
PORT = 5050           # Porta principal
```

**Nos clientes** (`client.py` e `ai_client.py`):
```python
PORT = 5050  # Deve coincidir com o servidor
# IP √© descoberto automaticamente via broadcast
```

### Configura√ß√£o do AI Bot

**No arquivo `ai_client.py`**, voc√™ pode alterar:

```python
def ask_ai(prompt, model="qwen2.5:4b"):  # Modelo padr√£o
```

**Modelos dispon√≠veis no Ollama:**
- `qwen2.5:4b` - Leve e r√°pido (recomendado)
- `llama3.2` - Modelo padr√£o da Meta
- `gemma2` - Modelo do Google
- `mistral` - Modelo franc√™s especializado
- `codellama` - Especializado em c√≥digo

**Para listar modelos instalados:**
```bash
ollama list
```

**Para baixar novos modelos:**
```bash
ollama pull nome-do-modelo
```

### Limites e Configura√ß√µes

**Limite de Arquivo:**
```python
if size > 10 * 1024 * 1024:  # 10MB padr√£o
```

**Timeout do AI Bot:**
```python
timeout=30  # 30 segundos para resposta da IA
```

**Porta de Descoberta:**
```python
5051  # Porta UDP para auto-descoberta
```

## üõ†Ô∏è Tecnologias Utilizadas

### Core do Chat
- **Socket Programming**: Comunica√ß√£o cliente-servidor TCP/UDP
- **Threading**: Manipula√ß√£o simult√¢nea de m√∫ltiplos clientes
- **JSON**: Protocolo de comunica√ß√£o estruturada
- **Base64**: Codifica√ß√£o de arquivos para transmiss√£o
- **Tkinter**: Interface gr√°fica para sele√ß√£o de arquivos

### AI Bot
- **Ollama**: Framework para executar LLMs localmente
- **Requests**: HTTP client para comunica√ß√£o com Ollama API
- **Auto-discovery**: Protocolo UDP para encontrar servidor automaticamente

## üìä Recursos T√©cnicos

### Arquitetura do Chat
- **Multi-threading**: Cada cliente √© tratado em thread separada
- **Sincroniza√ß√£o**: Uso de locks para evitar conflitos de entrada
- **Protocolo Personalizado**: Comunica√ß√£o estruturada em JSON
- **Gest√£o de Estado**: Controle de arquivos pendentes e usu√°rios online
- **Tratamento de Erros**: Recupera√ß√£o graceful de falhas de conex√£o
- **Descoberta Autom√°tica**: Localiza√ß√£o do servidor via broadcast UDP

### Arquitetura do AI Bot
- **Processamento Ass√≠ncrono**: Thread separada para monitorar mensagens
- **Cache de Conex√£o**: Reutiliza√ß√£o de conex√µes HTTP com Ollama
- **Fallback Graceful**: Continua funcionando mesmo sem Ollama
- **Logs Detalhados**: Monitoramento completo de atividades
- **Detec√ß√£o de Mensagens**: Parseamento inteligente de mensagens privadas

## üêõ Solu√ß√£o de Problemas

### Problemas Gerais

**"ConnectionRefusedError"**
- Certifique-se de que o servidor est√° rodando antes dos clientes
- Verifique se a porta 5050 n√£o est√° sendo usada por outro programa

**"ModuleNotFoundError: tkinter"**
- **Linux**: `sudo apt-get install python3-tk`
- **macOS**: Tkinter vem inclu√≠do com Python do python.org
- **Windows**: Geralmente inclu√≠do por padr√£o

**Arquivos n√£o s√£o recebidos**
- Verifique as permiss√µes da pasta
- Certifique-se de que h√° espa√ßo em disco suficiente

**"Usu√°rio n√£o encontrado"**
- Digite o nome exato do usu√°rio (case-sensitive)
- Use a op√ß√£o "Listar usu√°rios online" para ver nomes dispon√≠veis

### Problemas do AI Bot

**"‚ùå Ollama n√£o est√° rodando"**
- Execute `ollama serve` em um terminal separado
- Verifique se a porta 11434 n√£o est√° bloqueada

**"‚ùå Modelo n√£o encontrado"**
- Liste modelos: `ollama list`
- Baixe o modelo: `ollama pull qwen2.5:4b`

**"‚ùå Timeout ao aguardar resposta"**
- Modelo pode estar sendo carregado pela primeira vez (aguarde)
- Tente um modelo menor como `qwen2.5:4b`
- Verifique recursos do sistema (RAM, CPU)

**Bot n√£o responde**
- Verifique se o bot est√° online: liste usu√°rios (op√ß√£o 3)
- Certifique-se de enviar mensagem privada para "ChatBot" (exato)
- Verifique logs do AI Bot no terminal

**"‚ùå N√£o foi poss√≠vel conectar ao Ollama"**
- Verifique se Ollama est√° instalado: `ollama --version`
- Reinicie o servi√ßo: `ollama serve`
- Teste manualmente: `curl http://localhost:11434/api/tags`

## üéØ Fluxo de Funcionamento

### Descoberta Autom√°tica
1. Cliente envia broadcast UDP "CHAT_DISCOVER" na porta 5051
2. Servidor responde "CHAT_SERVER" com seu IP
3. Cliente conecta no IP descoberto na porta 5050

### Comunica√ß√£o Chat
1. Cliente envia nome em JSON: `{"type": "name", "message": "Jo√£o"}`
2. Servidor valida e confirma registro
3. Cliente pode enviar mensagens, arquivos ou listar usu√°rios
4. Servidor roteia mensagens baseado no campo "control"

### AI Bot
1. AI Bot conecta como cliente normal com nome "ChatBot"
2. Monitora mensagens privadas direcionadas a ele
3. Extrai pergunta e envia para Ollama API local
4. Retorna resposta formatada para o remetente

## ü§ù Contribuindo

1. Fa√ßa um fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/nova-funcionalidade`)
3. Commit suas mudan√ßas (`git commit -am 'Adiciona nova funcionalidade'`)
4. Push para a branch (`git push origin feature/nova-funcionalidade`)
5. Abra um Pull Request

## üìú Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo `LICENSE` para mais detalhes.

## üéØ Pr√≥ximas Funcionalidades

### Chat
- [ ] Salas de chat separadas
- [ ] Criptografia de mensagens
- [ ] Interface gr√°fica completa (GUI)
- [ ] Hist√≥rico persistente em banco de dados
- [ ] Notifica√ß√µes desktop
- [ ] Emojis e formata√ß√£o de texto
- [ ] Status de usu√°rio (online/ausente/ocupado)
- [ ] Mensagens com timestamps
- [ ] Sistema de modera√ß√£o

### AI Bot
- [ ] M√∫ltiplos bots especializados
- [ ] Comandos especiais (!help, !weather, etc.)
- [ ] Integra√ß√£o com outras APIs (tradu√ß√£o, clima, etc.)
- [ ] Mem√≥ria de conversas
- [ ] Personalidades diferentes por bot
- [ ] Gera√ß√£o de imagens
- [ ] An√°lise de sentimentos
- [ ] Resumo de conversas

## üí° Dicas de Uso

### Chat Geral
- Use nomes de usu√°rio √∫nicos para evitar conflitos
- Arquivos grandes podem demorar para ser transmitidos
- Mensagens privadas n√£o s√£o salvas no hist√≥rico global
- O servidor mant√©m log de todas as atividades no terminal

### AI Bot
- Seja espec√≠fico nas perguntas para melhores respostas
- O bot funciona melhor com perguntas em portugu√™s ou ingl√™s
- Evite perguntas muito complexas se usar modelos pequenos
- O primeiro uso pode ser mais lento (carregamento do modelo)
- Use modelos maiores para respostas mais elaboradas

### Performance
- Modelos menores (4B par√¢metros) s√£o mais r√°pidos
- Modelos maiores (7B+) d√£o respostas mais detalhadas
- Feche outros programas pesados quando usar o AI Bot
- SSD acelera significativamente o carregamento de modelos

## üîó Links √öteis

- [Ollama - Site Oficial](https://ollama.ai)
- [Ollama - Modelos Dispon√≠veis](https://ollama.ai/library)
- [Python Socket Programming](https://docs.python.org/3/library/socket.html)
- [Threading em Python](https://docs.python.org/3/library/threading.html)

---

‚≠ê **Se este projeto foi √∫til para voc√™, considere dar uma estrela no reposit√≥rio!**

ü§ñ **Experimente conversar com o ChatBot - pergunte qualquer coisa!**